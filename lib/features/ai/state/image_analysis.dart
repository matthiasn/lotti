import 'dart:async';
import 'dart:convert';
import 'dart:io';

import 'package:lotti/classes/journal_entities.dart';
import 'package:lotti/database/database.dart';
import 'package:lotti/features/ai/repository/cloud_inference_repository.dart';
import 'package:lotti/features/ai/repository/ollama_repository.dart';
import 'package:lotti/features/journal/state/entry_controller.dart';
import 'package:lotti/get_it.dart';
import 'package:lotti/utils/cache_extension.dart';
import 'package:lotti/utils/consts.dart';
import 'package:lotti/utils/image_utils.dart';
import 'package:riverpod_annotation/riverpod_annotation.dart';

part 'image_analysis.g.dart';

@riverpod
class AiImageAnalysisController extends _$AiImageAnalysisController {
  @override
  String build({
    required String id,
  }) {
    ref.cacheFor(entryCacheDuration);
    return '';
  }

  Future<void> analyzeImage() async {
    final provider = entryControllerProvider(id: id);
    final notifier = ref.read(provider.notifier);
    final entry = ref.watch(provider).value?.entry;

    if (entry is! JournalImage) {
      return;
    }

    await notifier.save();

    state = '';

    const prompt = '''
        Describe the image in detail, including its content, style, and any 
        relevant information that can be gleaned from the image.
        If the image is the screenshot of a website, then focus on the
        content of the website. Do not make up names.
        ''';

    final buffer = StringBuffer();
    final image = await getImage(entry);

    final useCloudInference =
        await getIt<JournalDb>().getConfigFlag(useCloudInferenceFlag);

    final model = useCloudInference
        ? 'google/gemma-3-27b-it-fast'
        : 'llama3.2-vision:latest';

    const temperature = 0.6;

    if (useCloudInference) {
      final config =
          await ref.read(cloudInferenceRepositoryProvider).getConfig();

      final stream =
          ref.read(cloudInferenceRepositoryProvider).generateWithImages(
                prompt,
                model: model,
                temperature: temperature,
                images: [image],
                config: config,
              );

      await for (final chunk in stream) {
        buffer.write(chunk.choices[0].delta.content);
        state = buffer.toString();
      }
    } else {
      final stream = ref.read(ollamaRepositoryProvider).generate(
        prompt,
        model: model,
        temperature: temperature,
        images: [image],
      );

      await for (final chunk in stream) {
        buffer.write(chunk.text);
        state = buffer.toString();
      }
    }

    final completeResponse =
        '```\nDisclaimer: the remainder of this entry until the next linked entry '
        "was generated by a multimodal AI model analysing the entry's image. "
        'Therefore, it may contain inaccuracies or errors. '
        'Please double-check the information before using it. '
        'If there are similar concepts to what is discussed in the history '
        'of a task, take the information into account but always assume that '
        'the information outside of this section is more accurate. \n```'
        '\n\n$state';

    await notifier.addTextToImage(completeResponse);
  }

  Future<String> getImage(JournalImage image) async {
    final fullPath = getFullImagePath(image);
    final bytes = await File(fullPath).readAsBytes();
    final base64String = base64Encode(bytes);

    return base64String;
  }
}
