# AI Chat Feature

An intelligent conversational interface for querying and interacting with Lotti tasks and productivity data. Users can ask questions about their task history, analyze patterns, and get AIâ€‘powered insights through natural language.

## ğŸ¯ Overview

The AI Chat feature enables users to:
- Query task summaries by date range using natural language
- Analyze productivity patterns and achievements
- Get AI-powered insights from their task history
- Interact through a streamlined chat interface with real-time streaming
- Speak instead of typing with builtâ€‘in voice input and transcription

## ğŸ—ï¸ Architecture

The feature follows a clean, modular architecture with clear separation of concerns:

```
lib/features/ai_chat/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ chat_message.dart               # Core message model
â”‚   â”œâ”€â”€ chat_session.dart               # Domain model for chat sessions
â”‚   â””â”€â”€ task_summary_tool.dart          # OpenAI function calling schema
â”œâ”€â”€ repository/
â”‚   â”œâ”€â”€ chat_repository.dart            # Core business logic orchestrator
â”‚   â”œâ”€â”€ chat_message_processor.dart     # Testable message processing
â”‚   â””â”€â”€ task_summary_repository.dart    # Task data retrieval
â””â”€â”€ ui/
    â”œâ”€â”€ controllers/                    # Riverpod state management
    â”‚   â””â”€â”€ chat_recorder_controller.dart # Audio recording + state machine
    â”œâ”€â”€ models/chat_ui_models.dart      # UI-specific models
    â”œâ”€â”€ pages/chat_modal_page.dart      # Modal integration
    â””â”€â”€ widgets/
        â”œâ”€â”€ chat_interface.dart         # Main chat UI with reasoning disclosure + voice controls
        â”œâ”€â”€ waveform_bars.dart          # Live waveform visualization of mic input
        â””â”€â”€ thinking_parser.dart        # Streaming-friendly reasoning parser
â”œâ”€â”€ services/
â”‚   â””â”€â”€ audio_transcription_service.dart # Gemini-based audio transcription
```

## ğŸ’¡ Key Features

### âœ… Intelligent Task Querying
- **Natural Language Processing**: Ask questions like "What did I work on last week?" or "Show me my achievements this month"
- **Date Range Intelligence**: Automatically interprets time periods (today, yesterday, last week, etc.)
- **Context Awareness**: Filters results by the selected category from the tasks page

### âœ… Advanced AI Capabilities
- **Model Selection**: Users must explicitly select an AI model from configured providers (e.g., Ollama, OpenAI-compatible, Gemini, etc.) per chat session - no automatic fallback
- **Function Calling**: Uses the `get_task_summaries` tool to retrieve relevant data
- **Streaming Markdown**: Tokens stream from providers and render incrementally as Markdown with a typing indicator
- **Collapsible Reasoning**: Hidden â€œthinkingâ€ blocks are parsed and shown behind a collapsed disclosure. Multiple segments are aggregated with a subtle divider and rendered with the same Markdown widget for consistent typography. For Gemini providers, nonâ€‘flash models may include a single consolidated thinking block before the visible answer (when enabled); flash models never surface thinking.
- **Copy Behavior**: Copying assistant messages strips hidden thinking by default.

### âœ… Voice Input & Transcription
- **Oneâ€‘tap Recording**: Tap the mic to start recording; see a live waveform
- **Accessible Controls**: Cancel (Esc shortcut) or Stop and transcribe
- **Smart Transcription**: Uses Gemini 2.5 Flash when available; falls back to the first audioâ€‘capable model for the configured Gemini provider
- **Flexible Send**: If a model is selected, the transcript autoâ€‘sends; otherwise itâ€™s inserted into the input field for review

### âœ… Sophisticated Data Processing
- **Complex Query Engine**: 4-step process to find work entries, resolve task relationships, and retrieve AI summaries
- **Duration Filtering**: Only includes meaningful work entries (15+ seconds for text entries, all audio entries)
- **Relationship Resolution**: Traces links between tasks and work entries through database relationships
- **Fallback Handling**: Provides basic summaries for tasks without AI-generated summaries

### âœ… Modern UI/UX
- **Material Design 3**: Consistent with app design language
- **Responsive Chat Interface**: Custom-built Flutter widgets with proper accessibility
- **Markdown Support**: Rich text rendering for AI responses with code syntax highlighting
- **Real-time Streaming**: Live token-by-token rendering; spacing tuned for readability
- **Session Management**: Create new chats, manage conversation history
- **Error Resilience**: Graceful error handling with retry and dismiss actions
- **Accessibility**: Disclosure is keyboard-accessible (Enter/Space) and exposed to screen readers. Avatars removed; user vs. assistant differentiated via asymmetric margins.

## ğŸ”§ Core Components

### ChatRepository
Central orchestrator handling:
- Session CRUD operations (in-memory storage)
- Real-time streaming: forwards content deltas to the UI while accumulating tool calls
- AI service integration through CloudInferenceRepository (providerâ€‘aware routing)
- Tool calling orchestration for task summaries and streaming of final responses

### ChatMessageProcessor
Extracted testable logic for:
- AI configuration management (provider + model resolution with caching for specific models)
- Message format conversion (internal â†” OpenAI formats)
- Stream processing: accumulate tool calls; expose streaming of final responses after tools
- Tool call processing and response handling
- Prompt building from conversation history
- No fallback mechanism - requires explicit model selection

### Reasoning & Copy Behavior

- Hidden reasoning is never rendered inline. The UI provides a single collapsed
  disclosure per assistant message. Multiple reasoning segments are concatenated
  with a Markdown horizontal rule (---) for readability.
- Copying assistant messages strips reasoning by default (only visible answer is
  copied). Copying from the reasoning disclosure copies the reasoning text.
- Gemini mapping: For nonâ€‘flash models (when enabled), at most one consolidated
  `<thinking>` block may appear before the visible answer; flash models never
  surface thinking. See `thinking_parser.dart` for the exact patterns supported
  and streaming/openâ€‘ended handling.

### TaskSummaryRepository
Complex data retrieval engine:
- Multi-step query process: Work Entries â†’ Links â†’ Tasks â†’ AI Summaries
- Date range filtering with ISO 8601 timestamp precision
- Duration-based work entry validation
- Task relationship resolution through EntryLink database relations
- AI summary extraction from AiResponseEntry records


## ğŸš€ Integration Points

### Main App Integration
- **Entry Point**: Psychology icon (ğŸ§ ) in tasks page app bar
- **Modal Design**: Bottom sheet taking ~80% of screen height
- **Category Context**: Inherits selected category from tasks page for filtering
- **Model Selection**: Required dropdown in the chat header; users must explicitly select a model before sending messages - no automatic fallback
- **State Management**: Reactive integration with Riverpod providers
- **Microphone UI**: Input area shows a mic button when empty; switches to waveform + Cancel/Stop controls while recording

### Permissions & Platform Notes
- **Microphone Access**: Requires microphone permission on supported platforms
- **Temporary Files**: Audio is recorded into an appâ€‘scoped temp directory and removed after processing or cancel
- **Keyboard Shortcuts**: Escape key cancels recording (focus requested when controls are visible)

### Data Layer Integration
- **JournalDb**: Direct database access for task and work entry retrieval
- **CloudInferenceRepository**: Leverages existing AI provider abstraction
- **AiConfigRepository**: Uses configured Gemini Flash model settings
- **LoggingService**: Comprehensive error tracking and debugging support

### AI Infrastructure Integration
- **Providers**: Unified interface for multiple providers (Ollama, OpenAI-compatible, Gemini, etc.)
- **Function Calling**: OpenAI-compatible tool definitions
- **Streaming**: Provider streams are forwarded as deltas to the UI
- **Error Handling**: Consistent with existing AI error patterns

### Provider Integration

The chat feature is providerâ€‘agnostic at the UI layer and routes inference via a shared orchestration layer:

- `CloudInferenceRepository` selects the appropriate adapter per provider:
  - Gemini â†’ `GeminiInferenceRepository` (native REST) with a robust streaming parser that handles SSE `data:` lines, NDJSON, and array framing. Emits OpenAIâ€‘compatible deltas and enforces the thinking visibility policy (nonâ€‘flash may include a single consolidated `<thinking>` block before visible content; flash models never include thinking).
  - Ollama â†’ `OllamaInferenceRepository` using the `/api/chat` endpoint for streaming and function calling.
  - OpenAIâ€‘compatible â†’ direct `openai_dart` streaming.
- The chat UI consumes OpenAIâ€‘compatible content deltas and uses `thinking_parser.dart` to hide/show reasoning without altering provider semantics.

## ğŸ“Š Technical Specifications

### Performance Characteristics
- **Response Initiation**: Fast first-token latency where supported by the provider
- **Streaming Updates**: Real-time content delivery as tokens arrive
- **Memory Efficiency**: Minimal overhead with proper stream disposal
- **Database Optimization**: Efficient queries with proper relationship traversal

### Data Processing Flow
1. **Work Entry Filtering**: Date range â†’ Duration validation â†’ Category filtering
2. **Link Resolution**: EntryLink relationships to find connected tasks
3. **Task Batch Retrieval**: Efficient bulk loading of related task entities
4. **AI Summary Extraction**: Latest AI responses with metadata preservation

### Model Integration
- **Model Selection**: Explicit selection required - select an eligible model per session (function-calling + text input required)
- **No Fallback**: System enforces model selection before sending messages - no automatic defaults
- **Providers**: Works with Ollama (local), OpenAI-compatible APIs, Gemini, and more (via unified config)
 - **Providers**: Works with Ollama (local), OpenAI-compatible APIs, Gemini, and more (via unified config and providerâ€‘aware adapters)
- **Function Calling**: OpenAI-compatible tool definitions
- **Context Management**: Prompt includes prior conversation context
- **Token Efficiency**: Optimized prompts for cost-effective usage

## ğŸ§ª Testing

Comprehensive test suite covering all components:

### Repository Tests
- **ChatRepository**: Integration tests for session management and message handling
- **ChatMessageProcessor**: Unit tests for message processing logic  
- **TaskSummaryRepository**: Complex data retrieval scenarios

### UI Tests
- **ChatInterface**: Widget testing for UI components
- **Voice Controls**: Chat input mic â†’ waveform â†’ cancel/stop flow with tooltips, keyboard handling, and disabled states while processing
- **WaveformBars**: Robust rendering tests (empty, large sets, bounds, sizing, theming)
- **ChatModalPage**: Page-level integration tests
- **Controllers**: State management validation

### Service Tests
- **UI Models**: Data model validation and conversion
- **AudioTranscriptionService**: Stream aggregation, model fallback, and error conditions

### Controller Tests
- **ChatRecorderController**: Permission handling, concurrent starts, temp file lifecycle, cleanup on cancel/dispose, timeout and error surfacing, amplitude normalization

### Test Coverage Highlights
- âœ… All business logic paths covered
- âœ… Error conditions and edge cases tested
- âœ… UI state management validation
- âœ… Database integration scenarios
- âœ… AI service integration mocking
- âœ… Complex data transformation testing

## ğŸ“± User Experience

### Chat Flow
1. **Initiation**: Tap brain icon (ğŸ§ ) in tasks page app bar
2. **Context Setup**: Chat automatically inherits selected category context
3. **Model Selection**: Required - must pick a model in the chat header before sending any messages
4. **Natural Queries**: Ask questions in natural language about tasks
5. **Real-time Responses**: Watch AI responses stream as formatted Markdown
6. **Session Management**: Continue conversations or start new chats

### Voice Flow
1. **Start**: Tap the mic when the input is empty
2. **Recording**: Waveform appears; use Cancel (or Esc) or Stop
3. **Processing**: Spinner shows while transcribing; input disabled
4. **Result**: Transcript is autoâ€‘sent if a model is selected, otherwise itâ€™s inserted into the input field

### Example Interactions
```
User: "What did I work on yesterday?"
AI: *Analyzes date range, retrieves work entries, finds linked tasks*
Response: "Yesterday you focused on [specific tasks with summaries]..."

User: "Show me my achievements this week"
AI: *Processes weekly timeframe, analyzes completed tasks*  
Response: "This week you accomplished [categorized achievements]..."

User: "What patterns do you see in my work?"
AI: *Analyzes productivity patterns*
Response: "Looking at your work patterns, I notice [insights]..."
```

## ğŸ”® Future Enhancements

### Planned Improvements

#### **High Priority - Persistence**
- **Database Persistence**: Replace in-memory session storage with SQLite persistence
  - **Current Limitation**: Chat sessions are lost when the app restarts
  - **Implementation Needed**: 
    - Create database schema for chat sessions and messages
    - Implement ChatRepository persistence layer
    - Add migration scripts for existing database
    - Maintain backward compatibility with current in-memory implementation
  - **Benefits**: Persistent chat history, better user experience, ability to resume conversations

#### **Performance Optimizations Completed** âœ…

The AI Chat feature has been optimized for production use with several key performance improvements:

- **âœ… AI Configuration Caching**: Efficient caching of AI provider and model configurations in `ChatMessageProcessor` (5â€‘minute cache)
- **âœ… Reduced DB Roundtrips**: Batch relationship lookups and bulk queries in `TaskSummaryRepository`
- **âœ… Session Search Performance**: Optimized in-memory filtering and nullâ€‘safe guards in session controllers

#### **Remaining Performance Considerations**

- **Task Query Volume**: Current implementation uses `limit: 10000` for work entry processing
  - **Current Status**: Acceptable for typical usage patterns, no immediate performance issues reported
  - **Future Enhancement**: Consider pagination if large datasets become problematic
  - **Monitoring**: Performance metrics show acceptable response times under normal load

#### **Feature Enhancements**
- **External Library Integration**: Consider migrating to `flutter_gen_ai_chat_ui` to reduce maintenance while keeping customization options
  
- **Multi-Category Support**: Enable querying across multiple categories simultaneously  
- **Export Functionality**: Export chat conversations as markdown or PDF
- **Textâ€‘toâ€‘Speech**: Add readâ€‘back for assistant responses
- **Advanced Analytics**: Pattern recognition and productivity insights
- **Task Modification**: Enable task creation and editing through chat commands

### Technical Enhancements
- **Caching Layer**: Implement query result caching for improved performance
- **Pagination**: Add pagination for large task result sets
- **Search Integration**: Connect with existing app search functionality
- **Offline Support**: Basic chat functionality when offline
- **Push Notifications**: Proactive insights and reminders

### UI/UX Improvements
- **Theme Customization**: Additional chat theme options
- **Message Search**: Search within chat conversation history
- **Quick Actions**: Predefined query templates for common questions
- **Accessibility**: Enhanced screen reader support and keyboard navigation
- **Mobile Optimization**: Improved responsive design for smaller screens

## ğŸ› ï¸ Development

### Key Dependencies
- **openai_dart**: OpenAI-compatible streaming, function calling
- **freezed_annotation**: Immutable data models with JSON serialization
- **flutter_riverpod**: State management and dependency injection
- **gpt_markdown**: Rich text rendering for AI responses
- **mocktail**: Comprehensive testing framework
- **record**: Crossâ€‘platform audio capture
- **path_provider**: Appâ€‘scoped temporary directories for audio files

### Architecture Principles
- **Clean Architecture**: Clear separation between domain, data, and presentation layers
- **SOLID Principles**: Single responsibility, dependency inversion, interface segregation
- **Testability**: All business logic is unit testable with dependency injection
- **Type Safety**: Full null safety with Freezed immutable models
- **Error Handling**: Comprehensive error boundaries with proper logging

### Code Quality Standards
- **Test Coverage**: Comprehensive test suite ensuring robust functionality across all components
- **Static Analysis**: Strict linting rules
- **Documentation**: Inline documentation for public APIs
- **Formatting**: Consistent code formatting with `dart format`
- **Modularity**: Loosely coupled components with clear interfaces

## ğŸ”§ How To Use
1. Configure at least one AI provider and add eligible models (function calling + text input) in settings.
2. Open the AI chat via the brain icon (ğŸ§ ) in the tasks page.
3. **Required**: Select a model from the header dropdown before sending any messages - there is no automatic fallback.
4. Ask a question in natural language; responses stream in as Markdown. If a response contains hidden reasoning, a collapsed â€œShow reasoningâ€ toggle appears above the message. Clicking it reveals the reasoning rendered as Markdown; multiple segments are separated by a subtle divider.

## â™¿ Accessibility & UX Notes

- Model selection is mandatory - the system will show an error if you try to send a message without selecting a model.
- Dropdown is disabled while the model is streaming to avoid accidental context changes.
- Error banner includes retry and dismiss actions when something goes wrong.
- Clear error messages guide users to select a model when attempting to send without one.

---

*This AI Chat feature represents a sophisticated integration of natural language processing, complex data querying, and modern Flutter UI patterns, providing users with an intelligent interface to explore their productivity data.*
